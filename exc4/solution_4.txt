Архитектурное решение по логированию

1. Необходимо собирать следующие логи:
- INFO Изменение статус заказа (заказ подтвержден, заказ взяли в работу, заказ завершен), логируем время, идентификатор, номер заказа
- ERROR Ответы с ошибкой 500 (система недоступна или не отвечает на запросы)
- WARNING Ответы с ошибкой 404 (система недоступна)
- INFO Время обработки каждой задачи в RabbitMQ 


2. Мотивация:

Логирование позволит:

- Увеличит безопасность, прослеживаемость и расследование источника инцидентов 
- Увеличит и улучит скорость отладки и запросов
- Минимизирует количество критических ошибок
- Усилит производительность путем измерения результатов времени обработки запросов в режиме реального времени
- Повысит уровень зрелости и качество разрабатываемого кода за счет опыта устранения предудыщих ошибок, выявленных в ходе логирования и изучения логов

3. Предлагаемое решение:


В качестве решения будет использовать стек ELK (ElasticSearch, Logstash, Kibana). Logstash - для сбора логов с анализируемых систем, ElasticSeacrh - база данных для анализ логов, хранения и поиска , Kibana - визуализация данных. 

Политика безопасности:
- Доступ к логам ограничен только для devops инженеров (доступ на чтение\изменение\удаление данных) и безопасности (доступ на чтение данных), тестировщиков (доступ на чтение данных)
- Логи не будут собираться для критичных данных - токены аутентификации, пароли, секреты, файлы, конфиденциальные данные, персональные данные

Хранение логов:
- Данные хранятся 2 месяца. В случае наличия инцидента - для конкретных данных мы пересохраняем данные на длительный срок
- Размер данных - не более 500 ГБ
- 

4. Анализ логов и алертинг

Алертинг и оповещение необходимо настроить и руководствоваться следующими принципами:

- Настройка количества подряд срабатываний (например, превышение заданного количества трафика или много ответов 500 от сервера, будет свидетельствовать о DDoS-атаке)
- Анализ логов на наличие конкретных срабатываний и сценариев атак (например, выполнение удаленного кода на операционной системе)
- Анализ логов с использованием Machine Learning на наличие нестандартных запросов
